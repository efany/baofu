# Web Crawler

A simple web crawler implemented in Python that respects robots.txt and implements polite crawling practices.

## Features

- Respects robots.txt
- Implements crawl delays
- Extracts links from web pages
- Follows only internal links
- Handles errors gracefully
- Configurable maximum pages to crawl

## Installation

1. Create a virtual environment: 